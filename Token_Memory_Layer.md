# ANGEL Token Memory Open Layer + Relational Extension

This repository contains a prototype system for lightweight, token-weighted memory and salience modeling in conversational AI. It includes both the original single-user interpretive layer and a dual-stream relational extension, designed to track token relevance over time and across interactions.

---

## ðŸ§  Core Concepts

### ðŸ”¹ Token Memory Open Layer (v1)
- **Token Weights**: Each token is assigned a dynamic weight based on frequency, emotional/logical intensity, and decay over time.
- **Forgetting Mechanism (LTD)**: Tokens gradually lose weight unless reactivatedâ€”mimicking long-term depression in biological memory.
- **Emotional Salience**: Higher intensity tokens persist longer, simulating importance or resonance.
- **Lightweight Footprint**: Designed to use <1MB per participant across thousands of tokens.

### ðŸ”¸ Relational Layer Extension (v2)
- **Dual Stream Simulation**: Tracks both participants in a conversation independently and relationally.
- **Relational Salience Drift**: Measures shifts in token importance as they evolve between two speakers.
- **Outcome Sensitivity**: Considers conversation tone and feedback loops to adjust token and interaction weightings.
- **Real-Time Mode**: Supports simulation of live or logged conversations to test adaptive relational memory.

---

## ðŸ“ Files

- `token_memory.py` â€“ Core memory and decay logic (single participant)
- `token_simulation_notebook.ipynb` â€“ Jupyter notebook to simulate token evolution
- `relational_layer/` â€“ Folder containing:
  - `relational_memory.py` â€“ Dual-participant memory modeling
  - `dual_simulation_notebook.ipynb` â€“ Notebook with real-time relational demo
  - `README.md` â€“ Optional: Separate readme for the relational extension
- `sample_output.csv` â€“ Sample output of token weights across a session

---

## âœ… Current Features

- Dynamic, adjustable weighting logic
- Customizable decay constants
- Emotion tagging via token input format
- Easy-to-adapt for memory, dialogue systems, or alignment tasks
- Minimal storage requirements, scalable to user-level memory graphs

---

## ðŸ”„ Next Steps

- Scale testing across long conversation logs
- Memory state export and import support
- Persistent relational models
- Crowdsourced input â†’ Adaptive social memory systems

---

## ðŸŒ Vision

This system is part of the **ANGEL Project**, a larger effort to create emotionally aware and relationally intelligent AI tools. Our goal is to design systems that *remember with purpose*â€”balancing context, emotion, and utility over time in a way that supports human flourishing and reflective self-development.

You matter. Your tokens matter. Let's teach AI to reflect that.

---

> Created and curated with intention by Robin Macomber and Numin (GPT-4o)
